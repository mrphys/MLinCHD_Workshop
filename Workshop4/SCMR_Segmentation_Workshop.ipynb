{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP5u5t5TRu3cqOqeVdXJbqk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Import & Extract Information from DICOM**"],"metadata":{"id":"gJyAp8MGTVtP"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"k2BbbFCcc-_T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pydicom\n","!pip install opencv-python\n","\n","from pydicom import dcmread\n","import numpy as np\n","from PIL import Image\n","import cv2\n","\n","# Path to the files\n","PATH = './drive/MyDrive/Colab Notebooks/SCMR Workshop/CMR/'\n","\n","# Load the sample DICOM image\n","ds = dcmread(PATH + 'Sample_Dicom.dcm')\n","\n","# Display the DICOM info\n","# print(ds)\n","\n","# Extract the metadata \"Spacing Between Slices\"\n","print('Extracting the metadata \"Spacing Between Slices\":\\n================================================')\n","\n","print('\\nMethod 1: using the name of the desired metadata')\n","print('Spacing Between Slices = {0}'.format(ds.SpacingBetweenSlices))\n","\n","print('\\nMethod 2: using the tag of the desired metadata')\n","element = ds[0x0018, 0x0088]\n","print(element)\n","print('Spacing Between Slices = {0}'.format(element.value))"],"metadata":{"id":"KnxBnofCTSq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract the image from the DICOM file\n","image = ds.pixel_array\n","\n","# Display the image dimensions\n","print('Image shape = {0}\\n'.format(image.shape))\n","\n","# Visualize the image\n","img = Image.fromarray(np.uint8(image), 'L')\n","img.save(PATH + 'Dicom_Image.png')\n","img"],"metadata":{"id":"zxAMw05iXmLr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["--------------------------------------------------------------------------"],"metadata":{"id":"Y_pQCii1b2qI"}},{"cell_type":"markdown","metadata":{"id":"OlJgDyvsWcSe"},"source":["**Libraries**"]},{"cell_type":"code","metadata":{"id":"DqGu80kmLaO1"},"source":["!pip install visualkeras\n","\n","\n","import numpy as np\n","from scipy.io import loadmat\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from keras.optimizers import Adam\n","from keras.models import Model\n","from keras.layers import Input, Dropout, concatenate\n","from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n","from keras import backend as K\n","\n","import visualkeras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0MaKtK_eWluP"},"source":["**Functions**"]},{"cell_type":"code","metadata":{"id":"rruQ337hN2jy"},"source":["# Average dice coefficient per batch\n","def dice_coef(y_true, y_pred, smooth=0.0):\n","    \"\"\"\n","    Average dice coefficient per batch\n","    :param y_true: True labels\n","    :param y_pred: Predicted labels\n","    :param smooth: a scalar (default to 0.0)\n","    :return: the Dice index\n","    \"\"\"\n","    axes = (1, 2, 3)\n","    intersection = K.sum(y_true * y_pred, axis=axes)\n","    summation = K.sum(y_true, axis=axes) + K.sum(y_pred, axis=axes)\n","\n","    return K.mean((2.0 * intersection + smooth) / (summation + smooth), axis=0)\n","\n","# Objective loss function to minimize, which is 1 minus the dice index\n","def dice_coef_loss(y_true, y_pred):\n","    return 1.0 - dice_coef(y_true, y_pred, smooth=0.1)\n","\n","# A simple U-Net model for image segmentation\n","def unet(pretrained_weights = None,input_size = (128, 128, 1)):\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(2, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(inputs)\n","    conv1 = Conv2D(2, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(4, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(pool1)\n","    conv2 = Conv2D(4, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(8, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(pool2)\n","    conv3 = Conv2D(8, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(16, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(pool3)\n","    conv4 = Conv2D(16, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(32, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(pool4)\n","    conv5 = Conv2D(32, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(16, 2, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(16, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(merge6)\n","    conv6 = Conv2D(16, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(conv6)\n","\n","    up7 = Conv2D(8, 2, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(8, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(merge7)\n","    conv7 = Conv2D(8, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(conv7)\n","\n","    up8 = Conv2D(4, 2, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(4, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(merge8)\n","    conv8 = Conv2D(4, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(conv8)\n","\n","    up9 = Conv2D(2, 2, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(2, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(merge9)\n","    conv9 = Conv2D(2, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(conv9)\n","    conv9 = Conv2D(2, 3, activation = 'tanh', padding = 'same', kernel_initializer = 'glorot_uniform')(conv9)\n","    output = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","    model = Model(inputs, output)\n","\n","    model.compile(optimizer = Adam(learning_rate = 0.001), loss = dice_coef_loss, metrics = [dice_coef])\n","\n","    if(pretrained_weights):\n","      model.load_weights(pretrained_weights)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Load the Data**"],"metadata":{"id":"3488RZgdPB9a"}},{"cell_type":"code","source":["# OUR DATA IS ALREADY PREPROCESSED AND AVAILABLE ONLINE AT:  https://github.com/saeedkarimi/Cardiac_MRI_Segmentation\n","# FOR THE SOURCE OF DATA AND STUDY, PLEASE REFER TO THIS PAPER:  https://link.springer.com/article/10.1186/s12968-020-00678-0 \n","\n","# Seed for random initializer\n","seed = 1234\n","np.random.seed(seed)\n","\n","# Contour type: 'LV' or 'RV'\n","contour_type = 'LV'\n","\n","# Random permutation of indices for 64 subjects. The first 45 are then selected as training and the rest are held as test set.\n","indices = np.random.permutation(64) + 1\n","\n","# Define the U-Net model\n","model = unet()\n","\n","# Print the model architecture\n","model.summary()\n","visualkeras.layered_view(model, legend=True, to_file=PATH + 'Model.png')\n","\n","# Initialize the training and test data\n","training_images = np.zeros(shape=(1, 128, 128))\n","training_masks = np.zeros(shape=(1, 128, 128))\n","test_images = np.zeros(shape=(1, 128, 128))\n","test_masks = np.zeros(shape=(1, 128, 128))\n","\n","# ==============================================================================\n","# Load the training data 'content/drive/MyDrive/Colab Notebooks/SCMR Workshop/CMR/'\n","for i in indices[0:45]:\n","  training_images = np.concatenate((training_images, loadmat(PATH + contour_type + '/Sbj_' + str(i) + '_' + contour_type + 'ED_image.mat')['image']), axis=0)\n","  training_masks = np.concatenate((training_masks, loadmat(PATH + contour_type + '/Sbj_' + str(i) + '_' + contour_type + 'ED_mask.mat')['mask']), axis=0)\n","\n","training_images = training_images[1:]\n","training_masks = training_masks[1:]\n","\n","# Reshape the data according to the model input size\n","training_images = np.expand_dims(training_images, axis=3)\n","training_masks = np.expand_dims(training_masks, axis=3)\n","\n","print('\\nTraining Data Size:')\n","print(training_images.shape)\n","print(training_masks.shape)\n","\n","# ==============================================================================\n","# Load the test data\n","for i in indices[45:]:\n","  test_images = np.concatenate((test_images, loadmat(PATH + contour_type + '/Sbj_' + str(i) + '_' + contour_type + 'ED_image.mat')['image']), axis=0)\n","  test_masks = np.concatenate((test_masks, loadmat(PATH + contour_type + '/Sbj_' + str(i) + '_' + contour_type + 'ED_mask.mat')['mask']), axis=0)\n","\n","test_images = test_images[1:]\n","test_masks = test_masks[1:]\n","\n","# Reshape the data according to the model input size\n","test_images = np.expand_dims(test_images, axis=3)\n","test_masks = np.expand_dims(test_masks, axis=3)\n","\n","print('\\nTest Data Size:')\n","print(test_images.shape)\n","print(test_masks.shape)\n","\n","img = cv2.imread(PATH + 'Model.png')\n","img = Image.fromarray(img.astype('uint8'))\n","img"],"metadata":{"id":"LHcuXzPjPFhu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CgG6Aunuvv0n"},"source":["**Training**"]},{"cell_type":"code","metadata":{"id":"Y21bXlmIONnq"},"source":["train_datagen = ImageDataGenerator(rotation_range=180, horizontal_flip=True, vertical_flip=True,\n","                                   featurewise_std_normalization=True, validation_split=0.3)\n","\n","# Compute quantities required for featurewise normalization\n","# (std, mean, and principal components if ZCA whitening is applied)\n","train_datagen.fit(training_images)\n","\n","# early_stopping = EarlyStopping(monitor='val_dice_coef', mode='max', verbose=1, patience=50, restore_best_weights=True)\n","\n","# Model checkpoints\n","checkpoints = ModelCheckpoint(filepath=PATH + 'weights.h5', save_weights_only=True, monitor='val_dice_coef', mode='max', save_best_only=True)\n","\n","# Fit the model on batches with real-time data augmentation:\n","history = model.fit(train_datagen.flow(training_images, training_masks, batch_size=16, subset='training'),\n","                    validation_data=train_datagen.flow(training_images, training_masks, batch_size=16, subset='validation'),\n","                    epochs=200, verbose=True, callbacks=[checkpoints])\n","\n","# Uncomment this if early_stopping is uncommented and included in the callbacks\n","# model.save(PATH + 'weights.h5')\n","\n","plt.plot(history.history['dice_coef'], 'r')\n","plt.plot(history.history['val_dice_coef'], 'b')\n","plt.title('Dice Per Epoch')\n","plt.ylabel('Dice')\n","plt.xlabel('Epoch')\n","plt.legend(['training dice', 'validation dice'], loc='upper left')\n","plt.grid(True)\n","plt.show()\n","plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9X8W7XBFv0Wi"},"source":["**Evaluation**"]},{"cell_type":"code","metadata":{"id":"g6nuvgmvvtY0"},"source":["# Clear the model graph\n","K.clear_session()\n","\n","# Load the model\n","model = unet(pretrained_weights = PATH + 'weights.h5', input_size = (128, 128, 1))\n","\n","# Predict segmentation masks for the test data using the trained model\n","predicted_masks = model.predict(test_masks, batch_size=4, verbose=True)\n","\n","# Quantize the pixel values to 0 and 1\n","predicted_masks = np.where(predicted_masks > 0.5, 1.0, 0.0).astype('float32')\n","\n","# Calculate the Dice metric\n","dice_metric = 0.0\n","for i in range(len(predicted_masks)):\n","  dice_metric += 2.0 * np.sum(np.multiply(test_masks[i], predicted_masks[i])) / (np.sum(test_masks[i]) + np.sum(predicted_masks[i]))\n","\n","dice_metric /= len(predicted_masks)\n","\n","print('\\nTest Dice Metric = {0}\\n'.format(dice_metric))\n","\n","# Visualize sample segmentations\n","rgb = np.zeros(shape=(128, 128, 3))\n","\n","image_number = 30\n","rgb[:, :, 0] = test_images[image_number, :, :, 0]\n","rgb[:, :, 1] = test_images[image_number, :, :, 0]\n","rgb[:, :, 2] = test_images[image_number, :, :, 0]\n","for i in range(128):\n","  for j in range(128):\n","    if test_masks[image_number, i, j, 0] == 1.0:\n","      rgb[i, j, 0] = 255.0\n","    if predicted_masks[image_number, i, j, 0] == 1.0:\n","      rgb[i, j, 1] = 255.0\n","img = Image.fromarray(rgb.astype('uint8'))\n","img.save(PATH + 'rgb.jpg')\n","img"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Studying Trained Models**"],"metadata":{"id":"wWI434mVK4J1"}},{"cell_type":"code","source":["# LV Experiments\n","#   Exp1: We use checkpoints with 200 epochs and a learning-rate of 0.001\n","#   Exp2: We use checkpoints with 1000 epochs and a learning-rate of 0.001\n","#   Exp3: We use checkpoints with 1000 epochs and a learning-rate of 0.001\n","#   Exp4: We use early-stopping with the patience of 50 and a learning-rate of 0.001\n","#   Exp5: We use checkpoints with 200 epochs and a learning-rate of 0.1\n","\n","# RV Experiments\n","#   Exp6: We use checkpoints with 200 epochs and a learning-rate of 0.001\n","#   Exp7: We use checkpoints with 1000 epochs and a learning-rate of 0.001\n","#   Exp8: We use early-stopping with the patience of 50 and a learning-rate of 0.001\n","\n","\n","EXP = 'Exp1'\n","\n","# Clear the model graph\n","K.clear_session()\n","\n","# Load the model\n","model = unet(pretrained_weights = PATH + EXP + '/weights.h5', input_size = (128, 128, 1))\n","\n","# Predict segmentation masks for the test data using the trained model\n","predicted_masks = model.predict(test_masks, batch_size=4, verbose=True)\n","\n","# Quantize the pixel values to 0 and 1\n","predicted_masks = np.where(predicted_masks > 0.5, 1.0, 0.0).astype('float32')\n","\n","# Calculate the Dice metric\n","dice_metric = 0.0\n","for i in range(len(predicted_masks)):\n","  dice_metric += 2.0 * np.sum(np.multiply(test_masks[i], predicted_masks[i])) / (np.sum(test_masks[i]) + np.sum(predicted_masks[i]))\n","\n","dice_metric /= len(predicted_masks)\n","\n","print('\\nTest Dice Metric = {0}\\n'.format(dice_metric))\n","\n","img = cv2.imread(PATH + EXP + '/train_val_curve.png')\n","img = Image.fromarray(img.astype('uint8'))\n","img"],"metadata":{"id":"cBbJIpx3LMKj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Visualization**"],"metadata":{"id":"LVbBtnyERswt"}},{"cell_type":"code","source":["# Visualize sample segmentations\n","rgb = np.zeros(shape=(128, 128, 3))\n","\n","image_number = 30\n","rgb[:, :, 0] = test_images[image_number, :, :, 0]\n","rgb[:, :, 1] = test_images[image_number, :, :, 0]\n","rgb[:, :, 2] = test_images[image_number, :, :, 0]\n","for i in range(128):\n","  for j in range(128):\n","    if test_masks[image_number, i, j, 0] == 1.0:\n","      rgb[i, j, 0] = 255.0\n","    if predicted_masks[image_number, i, j, 0] == 1.0:\n","      rgb[i, j, 1] = 255.0\n","img = Image.fromarray(rgb.astype('uint8'))\n","img"],"metadata":{"id":"gectmLqwRvXn"},"execution_count":null,"outputs":[]}]}